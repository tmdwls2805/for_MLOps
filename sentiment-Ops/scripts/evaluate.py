import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
import numpy as np

# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
model_path = "models/final"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path)
model.eval()

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
train_df = pd.read_csv("data/train.csv")
# í‰ê°€ìš© ë°ì´í„° (í•™ìŠµì— ì‚¬ìš©í•œ eval setê³¼ ë™ì¼)
eval_data = train_df[int(0.8 * len(train_df)):]

print("=" * 60)
print("ğŸ“Š ê°ì„± ë¶„ì„ ëª¨ë¸ í‰ê°€ ë¦¬í¬íŠ¸")
print("=" * 60)
print(f"\ní‰ê°€ ë°ì´í„°: {len(eval_data)}ê°œ ìƒ˜í”Œ\n")

# ì˜ˆì¸¡
predictions = []
labels = eval_data["label"].tolist()

for text in eval_data["text"]:
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        pred = torch.argmax(logits, dim=1).item()
        predictions.append(pred)

# ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
accuracy = accuracy_score(labels, predictions)
precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')
conf_matrix = confusion_matrix(labels, predictions)

print(f"âœ… ì •í™•ë„ (Accuracy): {accuracy:.2%}")
print(f"âœ… ì •ë°€ë„ (Precision): {precision:.2%}")
print(f"âœ… ì¬í˜„ìœ¨ (Recall): {recall:.2%}")
print(f"âœ… F1 ìŠ¤ì½”ì–´: {f1:.4f}")
print(f"\ní˜¼ë™ í–‰ë ¬ (Confusion Matrix):")
print(conf_matrix)
print("\n[í–‰: ì‹¤ì œ ë ˆì´ë¸”, ì—´: ì˜ˆì¸¡ ë ˆì´ë¸”]")
print("[[TN, FP],")
print(" [FN, TP]]")

# ìƒ˜í”Œë³„ ì˜ˆì¸¡ ê²°ê³¼
print("\n" + "=" * 60)
print("ğŸ“ ìƒ˜í”Œë³„ ì˜ˆì¸¡ ê²°ê³¼")
print("=" * 60)

for idx, (text, true_label, pred_label) in enumerate(zip(eval_data["text"], labels, predictions)):
    status = "âœ…" if true_label == pred_label else "âŒ"
    sentiment_true = "ê¸ì •" if true_label == 1 else "ë¶€ì •"
    sentiment_pred = "ê¸ì •" if pred_label == 1 else "ë¶€ì •"
    
    print(f"\n{status} ìƒ˜í”Œ {idx + 1}:")
    print(f"   í…ìŠ¤íŠ¸: {text}")
    print(f"   ì‹¤ì œ: {sentiment_true} (label={true_label})")
    print(f"   ì˜ˆì¸¡: {sentiment_pred} (label={pred_label})")

# ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ë¡œ í…ŒìŠ¤íŠ¸
print("\n" + "=" * 60)
print("ğŸ§ª ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸")
print("=" * 60)

test_texts = [
    "This movie is amazing!",
    "I hate this product.",
    "It's okay, nothing special.",
    "Best experience ever!",
    "Terrible service, very disappointed."
]

for text in test_texts:
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = torch.softmax(logits, dim=1)
        pred = torch.argmax(logits, dim=1).item()
        confidence = probs[0][pred].item()
    
    sentiment = "ê¸ì • ğŸ˜Š" if pred == 1 else "ë¶€ì • ğŸ˜"
    print(f"\ní…ìŠ¤íŠ¸: {text}")
    print(f"ì˜ˆì¸¡: {sentiment} (ì‹ ë¢°ë„: {confidence:.2%})")

print("\n" + "=" * 60)
print("í‰ê°€ ì™„ë£Œ!")
print("=" * 60)
